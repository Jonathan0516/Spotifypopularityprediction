{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, silhouette_score, davies_bouldin_score, f1_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "from enum import Enum\n",
    "from kneed import KneeLocator\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data = pd.read_csv('datasets/merged_spotify_dataset.csv')\n",
    "song_data.info()\n",
    "song_data.describe()\n",
    "spotify_song_data = song_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_song_data['Date'] = pd.to_datetime(spotify_song_data['Date'], format='%d/%m/%Y')\n",
    "\n",
    "spotify_song_data['Data_Month'] = spotify_song_data['Date'].dt.to_period('M')\n",
    "\n",
    "spotify_song_data.head()\n",
    "\n",
    "average_monthly_points = spotify_song_data.groupby(['id', 'Data_Month'])['Points (Total)'].mean().reset_index()\n",
    "\n",
    "average_monthly_points.rename(columns={'Points (Total)': 'Average_Points'}, inplace=True)\n",
    "\n",
    "monthly_data = pd.merge(spotify_song_data, average_monthly_points, on=['id', 'Data_Month'], how='left')\n",
    "\n",
    "columns_to_drop = ['Points (Total)', 'Points (Ind for each Artist/Nat)', 'Date', 'Rank']\n",
    "monthly_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "monthly_data.drop_duplicates(inplace=True)\n",
    "monthly_unique_songs = monthly_data.drop_duplicates(subset=['id', 'Data_Month'])\n",
    "\n",
    "monthly_unique_songs = monthly_unique_songs.dropna(subset=monthly_unique_songs.columns.difference(['genres']))\n",
    "\n",
    "monthly_unique_songs.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_average_points = monthly_unique_songs.groupby('Artists')['Average_Points'].mean()\n",
    "\n",
    "monthly_unique_songs['Artist_Average_Points'] = monthly_unique_songs['Artists'].map(artist_average_points)\n",
    "\n",
    "monthly_unique_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main genres for categorization\n",
    "main_genres = ['pop', 'rock', 'hip hop', 'rap', 'r&b', 'country', 'jazz', 'classical', 'electronic', 'dance', 'latin', 'reggae', 'blues', 'soul', 'funk', 'metal', 'punk', 'folk', 'world', 'indie', 'corrido']\n",
    "\n",
    "def categorize_genre(sub_genres):\n",
    "    sub_genres_list = str(sub_genres).lower().split(',')\n",
    "    for main_genre in main_genres:\n",
    "        if any(main_genre in sub_genre for sub_genre in sub_genres_list):\n",
    "            return main_genre\n",
    "    return 'other'\n",
    "\n",
    "monthly_unique_songs['General_Genre'] = monthly_unique_songs['genres'].apply(categorize_genre)\n",
    "\n",
    "columns_to_drop = ['# of Artist', 'Artist (Ind.)', '# of Nationality', 'Nationality', \n",
    "                   'Points (Ind for each Artist/Nat)', 'Points (Total)', 'Song URL', 'genres']\n",
    "\n",
    "monthly_unique_songs = monthly_unique_songs.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "monthly_unique_songs.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean popularity\n",
    "mean_popularity = monthly_unique_songs['popularity'].mean()\n",
    "\n",
    "monthly_unique_songs['is_popular'] = (monthly_unique_songs['popularity'] >= mean_popularity).astype(int)\n",
    "mean_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "monthly_unique_songs['sentiment'] = monthly_unique_songs['Title'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "\n",
    "cut = pd.cut(\n",
    "    monthly_unique_songs['sentiment'],\n",
    "    [-np.inf, -.01, .01, np.inf],\n",
    "    labels=['negative', 'neutral', 'positive']\n",
    ")\n",
    "\n",
    "monthly_unique_songs['polarity'] = cut.values\n",
    "\n",
    "monthly_unique_songs[['polarity', 'sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing one-hot encoding for the specified columns\n",
    "one_hot_continent = pd.get_dummies(monthly_unique_songs['Continent'], prefix='Continent')\n",
    "one_hot_key = pd.get_dummies(monthly_unique_songs['key'], prefix='Key')\n",
    "one_hot_mode = pd.get_dummies(monthly_unique_songs['mode'], prefix='Mode')\n",
    "one_hot_time_signature = pd.get_dummies(monthly_unique_songs['time_signature'], prefix='Time_Signature')\n",
    "one_hot_polarity = pd.get_dummies(monthly_unique_songs['polarity'], prefix='Polarity')\n",
    "one_hot_genre = pd.get_dummies(monthly_unique_songs['General_Genre'], prefix='General_Genre')\n",
    "\n",
    "\n",
    "# Concatenating the one-hot encoded columns with the original dataframe\n",
    "monthly_unique_songs = pd.concat([monthly_unique_songs, one_hot_continent, one_hot_key, one_hot_mode, one_hot_time_signature, one_hot_polarity, one_hot_genre], axis=1)\n",
    "monthly_unique_songs.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict popularity of this database(75%learn 25%test)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Selecting the features for the model\n",
    "# feature_columns = ['Danceability', 'Energy', 'Loudness', 'Speechiness', 'Acousticness', \n",
    "#                            'Instrumentalness', 'Valence', 'tempo', 'Artist_Average_Points', 'duration_ms'] + \\\n",
    "#                   [col for col in monthly_unique_songs.columns if col.startswith('Key_')] + \\\n",
    "#                   [col for col in monthly_unique_songs.columns if col.startswith('Continent_')] + \\\n",
    "#                   [col for col in monthly_unique_songs.columns if col.startswith('Mode_')] + \\\n",
    "#                   [col for col in monthly_unique_songs.columns if col.startswith('Time_Signature_')] + \\\n",
    "#                   [col for col in monthly_unique_songs.columns if col.startswith('Polarity_')] + \\\n",
    "#                   [col for col in monthly_unique_songs.columns if col.startswith('General_Genre_')]\n",
    "\n",
    "\n",
    "# target_column = 'is_popular'\n",
    "\n",
    "\n",
    "# X = monthly_unique_songs[feature_columns]\n",
    "# y = monthly_unique_songs[target_column]\n",
    "\n",
    "# X = X.fillna(X.mean())\n",
    "\n",
    "# # Splitting the data into training and testing sets (75% training, 25% testing)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# According to the musical feature(2017-2022) to predict future popular music 2023 \n",
    "monthly_unique_songs['Data_Month'] = pd.to_datetime(monthly_unique_songs['Data_Month'].dt.to_timestamp())\n",
    "\n",
    "# Splitting the dataset into training (before 2023) and testing (2023)\n",
    "train_data = monthly_unique_songs[(monthly_unique_songs['Data_Month'] >= '2017-01') & (monthly_unique_songs['Data_Month'] < '2023-01')]\n",
    "test_data = monthly_unique_songs[monthly_unique_songs['Data_Month'] >= '2023-01']\n",
    "target_column = 'is_popular'\n",
    "# Selecting the features for the model\n",
    "feature_columns = ['Danceability', 'Energy', 'Loudness', 'Speechiness', 'Acousticness', \n",
    "                   'Instrumentalness', 'Valence', 'tempo', 'Artist_Average_Points', 'duration_ms'] + \\\n",
    "                  [col for col in monthly_unique_songs.columns if col.startswith('Key_')] + \\\n",
    "                  [col for col in monthly_unique_songs.columns if col.startswith('Continent_')] + \\\n",
    "                  [col for col in monthly_unique_songs.columns if col.startswith('Mode_')] + \\\n",
    "                  [col for col in monthly_unique_songs.columns if col.startswith('Time_Signature_')] + \\\n",
    "                  [col for col in monthly_unique_songs.columns if col.startswith('Polarity_')] + \\\n",
    "                  [col for col in monthly_unique_songs.columns if col.startswith('General_Genre_')]\n",
    "\n",
    "# Extracting features and target for training and testing data\n",
    "X_train = train_data[feature_columns].fillna(train_data[feature_columns].mean())\n",
    "y_train = train_data[target_column]\n",
    "\n",
    "X_test = test_data[feature_columns].fillna(test_data[feature_columns].mean())\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "accuracy, conf_matrix, class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "class_report_rf = classification_report(y_test, y_pred_rf)\n",
    "y_prob_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "roc_auc_rf = roc_auc_score(y_test, y_prob_rf)\n",
    "\n",
    "accuracy_rf, conf_matrix_rf, class_report_rf, roc_auc_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# plot feature importance\n",
    "ax = plot_importance(model)\n",
    "fig = ax.figure\n",
    "fig.set_size_inches(20, 15)\n",
    "#plot_importance(model)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log_reg = log_reg_model.predict(X_test)\n",
    "\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "conf_matrix_log_reg = confusion_matrix(y_test, y_pred_log_reg)\n",
    "class_report_log_reg = classification_report(y_test, y_pred_log_reg)\n",
    "\n",
    "y_prob_log_reg = log_reg_model.predict_proba(X_test)[:, 1]\n",
    "roc_auc_log_reg = roc_auc_score(y_test, y_prob_log_reg)\n",
    "\n",
    "accuracy_log_reg, conf_matrix_log_reg, class_report_log_reg, roc_auc_log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "log_reg_model_simplified = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg_model_simplified.fit(X_train.iloc[:1000], y_train.iloc[:1000])  # Using a subset of the data\n",
    "\n",
    "y_prob_simplified = log_reg_model_simplified.predict_proba(X_test.iloc[:1000])[:, 1]\n",
    "fpr_simplified, tpr_simplified, thresholds_simplified = roc_curve(y_test.iloc[:1000], y_prob_simplified)\n",
    "roc_auc_simplified = auc(fpr_simplified, tpr_simplified)\n",
    "\n",
    "# Plotting the ROC Curve\n",
    "plt.figure()\n",
    "plt.plot(fpr_simplified, tpr_simplified, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_simplified)\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
