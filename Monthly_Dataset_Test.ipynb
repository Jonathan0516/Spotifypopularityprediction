{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, silhouette_score, davies_bouldin_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from enum import Enum\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data = pd.read_csv('datasets/Spotify_Dataset_V3.csv', delimiter=';')\n",
    "song_data.info()\n",
    "song_data.describe()\n",
    "spotify_song_data = song_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_song_data['Date'] = pd.to_datetime(spotify_song_data['Date'], format='%d/%m/%Y')\n",
    "\n",
    "spotify_song_data['Data_Month'] = spotify_song_data['Date'].dt.to_period('M')\n",
    "\n",
    "spotify_song_data.head()\n",
    "\n",
    "average_monthly_points = spotify_song_data.groupby(['id', 'Data_Month'])['Points (Total)'].mean().reset_index()\n",
    "\n",
    "average_monthly_points.rename(columns={'Points (Total)': 'Average_Points'}, inplace=True)\n",
    "\n",
    "monthly_data = pd.merge(spotify_song_data, average_monthly_points, on=['id', 'Data_Month'], how='left')\n",
    "\n",
    "columns_to_drop = ['Points (Total)', 'Points (Ind for each Artist/Nat)', 'Date', 'Rank']\n",
    "monthly_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "monthly_data.drop_duplicates(inplace=True)\n",
    "\n",
    "monthly_data.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr_matrix = monthly_data.corr()\n",
    "\n",
    "corr_matrix = corr_matrix.iloc[1:, :-1]\n",
    "\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k = 1)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "sns.heatmap(corr_matrix, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n",
    "\n",
    "plt.title(\"Numeric Feature Correlation Heatmap\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting year from the 'Data_Month' column\n",
    "monthly_data['Year'] = monthly_data['Data_Month'].dt.year\n",
    "\n",
    "yearly_avg_points = monthly_data.groupby(['Artist (Ind.)', 'Year'])['Average_Points'].mean().reset_index()\n",
    "\n",
    "yearly_avg_points_pivot = yearly_avg_points.pivot_table(index='Artist (Ind.)', columns='Year', values='Average_Points').reset_index()\n",
    "\n",
    "for year in range(2017, 2023):\n",
    "    yearly_avg_points_pivot[f'Growth_{year+1}'] = ((yearly_avg_points_pivot[year+1] - yearly_avg_points_pivot[year]) / yearly_avg_points_pivot[year]) * 100\n",
    "\n",
    "yearly_avg_points_pivot.fillna(0, inplace=True)  \n",
    "yearly_avg_points_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Initializing the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#Encoding the 'Artist (Ind.)' column\n",
    "yearly_avg_points_pivot['Artist_Encoded'] = label_encoder.fit_transform(yearly_avg_points_pivot['Artist (Ind.)'])\n",
    "\n",
    "yearly_avg_points_pivot[['Artist (Ind.)', 'Artist_Encoded']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_75th_percentile = yearly_avg_points_pivot[2023].quantile(0.75)\n",
    "yearly_avg_points_pivot['Popular'] = (yearly_avg_points_pivot[2023] > threshold_75th_percentile).astype(int)\n",
    "yearly_avg_points_pivot[['Artist (Ind.)', 2023, 'Popular']].head()\n",
    "threshold_75th_percentile_2021 = yearly_avg_points_pivot[2021].quantile(0.75)\n",
    "threshold_75th_percentile_2022 = yearly_avg_points_pivot[2022].quantile(0.75)\n",
    "yearly_avg_points_pivot['Popular_2021'] = (yearly_avg_points_pivot[2021] > threshold_75th_percentile_2021).astype(int)\n",
    "yearly_avg_points_pivot['Popular_2022'] = (yearly_avg_points_pivot[2022] > threshold_75th_percentile_2022).astype(int)\n",
    "\n",
    "yearly_avg_points_pivot[['Artist (Ind.)', 2021, 'Popular_2021', 2022, 'Popular_2022']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2022 = monthly_data[monthly_data['Year'] == 2022]\n",
    "monthly_avg_points_2022 = data_2022.groupby(['Artist (Ind.)', 'Data_Month'])['Average_Points'].mean().reset_index()\n",
    "monthly_avg_points_2022.sort_values(by=['Artist (Ind.)', 'Data_Month'], inplace=True)\n",
    "\n",
    "monthly_avg_points_2022['Monthly_Growth_Rate'] = monthly_avg_points_2022.groupby('Artist (Ind.)')['Average_Points'].pct_change().fillna(0) * 100\n",
    "\n",
    "avg_monthly_growth_rate_2022 = monthly_avg_points_2022.groupby('Artist (Ind.)')['Monthly_Growth_Rate'].mean().reset_index()\n",
    "\n",
    "avg_monthly_growth_rate_2022.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = avg_monthly_growth_rate_2022.merge(yearly_avg_points_pivot[['Artist (Ind.)', 'Popular']], on='Artist (Ind.)', how='left')\n",
    "\n",
    "merged_data['Popular'].fillna(0, inplace=True)\n",
    "\n",
    "X = merged_data[['Monthly_Growth_Rate']]\n",
    "y = merged_data['Popular']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the total average points for each artist in 2022\n",
    "total_avg_points_2022 = data_2022.groupby('Artist (Ind.)')['Average_Points'].mean().reset_index()\n",
    "total_avg_points_2022.rename(columns={'Average_Points': 'Total_Avg_Points_2022'}, inplace=True)\n",
    "\n",
    "merged_data = merged_data.merge(total_avg_points_2022, on='Artist (Ind.)', how='left')\n",
    "\n",
    "merged_data['Total_Avg_Points_2022'].fillna(0, inplace=True)\n",
    "\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "accuracy, conf_matrix, class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2022 = monthly_data[monthly_data['Year'] == 2022]\n",
    "\n",
    "monthly_avg_points_2022 = data_2022.groupby(['Artist (Ind.)', 'Data_Month'])['Average_Points'].mean().reset_index()\n",
    "\n",
    "monthly_avg_points_2022.sort_values(by=['Artist (Ind.)', 'Data_Month'], inplace=True)\n",
    "\n",
    "monthly_avg_points_2022['Monthly_Growth_Rate'] = monthly_avg_points_2022.groupby('Artist (Ind.)')['Average_Points'].pct_change().fillna(0) * 100\n",
    "\n",
    "avg_monthly_growth_rate_2022 = monthly_avg_points_2022.groupby('Artist (Ind.)')['Monthly_Growth_Rate'].mean().reset_index()\n",
    "\n",
    "avg_monthly_growth_rate_2022.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = merged_data[['Total_Avg_Points_2022']]\n",
    "y_new = merged_data['Popular']\n",
    "\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, y_new, test_size=0.3, random_state=42)\n",
    "\n",
    "log_reg_new = LogisticRegression(random_state=42)\n",
    "log_reg_new.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_new = log_reg_new.predict(X_test_new)\n",
    "\n",
    "accuracy_new = accuracy_score(y_test_new, y_pred_new)\n",
    "conf_matrix_new = confusion_matrix(y_test_new, y_pred_new)\n",
    "class_report_new = classification_report(y_test_new, y_pred_new)\n",
    "\n",
    "accuracy_new, conf_matrix_new, class_report_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_2022 = set(data_2022['Artist (Ind.)'].unique())\n",
    "artists_2023 = set(monthly_data[monthly_data['Year'] == 2023]['Artist (Ind.)'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_only_in_2022 = artists_2022 - artists_2023\n",
    "\n",
    "num_artists_only_in_2022 = len(artists_only_in_2022)\n",
    "num_artists_only_in_2022\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "artists_both_years = artists_2022.intersection(artists_2023)\n",
    "data_both_years = monthly_data[monthly_data['Artist (Ind.)'].isin(artists_both_years)]\n",
    "\n",
    "yearly_avg_points_both_years = data_both_years.groupby(['Artist (Ind.)', 'Year'])['Average_Points'].mean().reset_index()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "yearly_avg_points_both_years['Artist_Code'] = encoder.fit_transform(yearly_avg_points_both_years['Artist (Ind.)'])\n",
    "\n",
    "threshold_2022_both_years = yearly_avg_points_both_years[yearly_avg_points_both_years['Year'] == 2022]['Average_Points'].quantile(0.75)\n",
    "yearly_avg_points_both_years['Popular'] = np.where((yearly_avg_points_both_years['Year'] == 2022) & \n",
    "                                                  (yearly_avg_points_both_years['Average_Points'] > threshold_2022_both_years), 1, 0)\n",
    "data_for_model_both_years = yearly_avg_points_both_years.merge(avg_monthly_growth_rate_2022, on='Artist (Ind.)', how='inner')\n",
    "data_for_model_both_years = data_for_model_both_years.merge(total_avg_points_2022, on='Artist (Ind.)', how='inner')\n",
    "data_train_both_years = data_for_model_both_years[data_for_model_both_years['Year'] == 2022]\n",
    "X_final_both_years = data_train_both_years[['Artist_Code', 'Monthly_Growth_Rate', 'Total_Avg_Points_2022']]\n",
    "y_final_both_years = data_train_both_years['Popular']\n",
    "\n",
    "X_train_final_both, X_test_final_both, y_train_final_both, y_test_final_both = train_test_split(\n",
    "    X_final_both_years, y_final_both_years, test_size=0.3, random_state=42, stratify=y_final_both_years)\n",
    "\n",
    "log_reg_final_both = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg_final_both.fit(X_train_final_both, y_train_final_both)\n",
    "\n",
    "y_pred_final_both = log_reg_final_both.predict(X_test_final_both)\n",
    "accuracy_final_both = accuracy_score(y_test_final_both, y_pred_final_both)\n",
    "conf_matrix_final_both = confusion_matrix(y_test_final_both, y_pred_final_both)\n",
    "class_report_final_both = classification_report(y_test_final_both, y_pred_final_both)\n",
    "\n",
    "accuracy_final_both, conf_matrix_final_both, class_report_final_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
