{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd9bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from enum import Enum\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cace29",
   "metadata": {},
   "source": [
    "###### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b756c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data = pd.read_csv('datasets/Spotify_Dataset_V3.csv', delimiter=';')\n",
    "song_data.info()\n",
    "song_data.describe()\n",
    "spotify_song_data = song_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf2a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "spotify_song_data_info = spotify_song_data.info()\n",
    "spotify_song_data_head = spotify_song_data.head()\n",
    "\n",
    "(spotify_song_data_info, spotify_song_data_head)\n",
    "\n",
    "# Dropping the unuse columns\n",
    "columns_to_drop = ['# of Artist', 'id', 'Song URL']\n",
    "spotify_song_data_reduced = spotify_song_data.drop(columns=columns_to_drop, errors='ignore')\n",
    "spotify_song_data_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300bffb2",
   "metadata": {},
   "source": [
    "#### What drives cross-regional popularity of music; is it the artist, or something about the song?\n",
    "1. Identify the correlation between musical attribution and point\n",
    "2. FInd out the correlation between artists, nationality and point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e12f13c",
   "metadata": {},
   "source": [
    "Firstly, identify the correlation between musical attribution and point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr_matrix = spotify_song_data_reduced.corr()\n",
    "\n",
    "# remove the first row and last column\n",
    "corr_matrix = corr_matrix.iloc[1:, :-1]\n",
    "\n",
    "# Generate a mask\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k = 1)\n",
    "\n",
    "# Set matplotlib figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Generate colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap\n",
    "sns.heatmap(corr_matrix, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n",
    "\n",
    "# Title and display the plot\n",
    "plt.title(\"Numeric Feature Correlation Heatmap\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f9b23d",
   "metadata": {},
   "source": [
    "We can clearly see that there are not any correlation between musical attribution and Point almost\n",
    "But we can still concentrate on whether exists the correlation between musical attribution and different nationalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99849c5c",
   "metadata": {},
   "source": [
    "Due to the data of nationalities are too many, so we transfer them to continent, identify the correlaiton of continent and attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b21194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating means of the musical features in each continent\n",
    "musical_features = ['Danceability', 'Energy', 'Loudness', 'Speechiness', \n",
    "                    'Acousticness', 'Instrumentalness', 'Valence']\n",
    "mean_values_per_continent = spotify_song_data.groupby('Continent')[musical_features].mean()\n",
    "\n",
    "# Displaying the means\n",
    "mean_values_per_continent.sort_values(by='Danceability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac99349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set matplotlib figure\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Create subplots for each musical feature\n",
    "for i, feature in enumerate(musical_features, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.boxplot(x='Continent', y=feature, data=spotify_song_data)\n",
    "    plt.title(f'Boxplot of {feature} by Continent')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c35828",
   "metadata": {},
   "source": [
    "Danceability：Latin-America的歌曲在可舞动性上的中位数最高\n",
    "\n",
    "Energy：不同大陆在能量特质上的分布差异较大，其中“Unknown”大陆的中位数最高\n",
    "\n",
    "Loudness：大多数大陆在响度上的分布相近，但“Anglo-America”稍微较低\n",
    "\n",
    "Speechiness：Latin-America的歌曲在说唱性上的分布最高\n",
    "\n",
    "Acousticness：Latin-America的歌曲在声学性上的中位数也较高\n",
    "\n",
    "Instrumentalness：“Unknown”大陆在乐器性上的中位数最高\n",
    "\n",
    "Valence：Latin-America在正向情感度上的分布也较高"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdceae7",
   "metadata": {},
   "source": [
    "Next, we find out if there are corellation between artist and point\n",
    "\n",
    "Since the 'Artists' field seems to contain multiple artists in some records, we will use 'Artist (Ind.)' for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa9412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the average points for each artist\n",
    "average_points_per_artist = spotify_song_data.groupby('Artist (Ind.)')['Points (Total)'].mean()\n",
    "\n",
    "# Converting the series to a dataframe and resetting the index\n",
    "average_points_df = average_points_per_artist.reset_index()\n",
    "\n",
    "# Renaming the columns for clarity\n",
    "average_points_df.rename(columns={'Points (Total)': 'Average Points'}, inplace=True)\n",
    "\n",
    "# Displaying the first few rows of the dataframe\n",
    "average_points_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ccd582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the top artists based on average points for visualization\n",
    "top_artists = average_points_df.nlargest(20, 'Average Points')\n",
    "\n",
    "# Creating a bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(top_artists['Artist (Ind.)'], top_artists['Average Points'], color='skyblue')\n",
    "plt.xlabel('Average Points')\n",
    "plt.title('Top 20 Artists with Highest Average Points')\n",
    "plt.gca().invert_yaxis()  # To have the highest on top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ee45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by artist and calculating the total points for each artist\n",
    "artist_total_points = spotify_song_data.groupby('Artist (Ind.)')['Points (Ind for each Artist/Nat)'].sum()\n",
    "\n",
    "# Sorting the artists by total points and selecting the top 20\n",
    "top_artists = artist_total_points.sort_values(ascending=False).head(20)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=top_artists.values, y=top_artists.index, palette='viridis')\n",
    "plt.xlabel('Total Points (Ind for each Artist/Nat)', fontsize=12)\n",
    "plt.ylabel('Artist', fontsize=12)\n",
    "plt.title('Top 20 Artists Based on Total Points (Ind for each Artist/Nat)', fontsize=15)\n",
    "plt.grid(axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5f7274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculating average Points per continent\n",
    "avg_points_per_continent = spotify_song_data.groupby('Continent')['Points (Ind for each Artist/Nat)'].mean().sort_values(ascending=False)\n",
    "\n",
    "# Plotting boxplot for Points distribution per continent\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=spotify_song_data, x='Continent', y='Points (Ind for each Artist/Nat)', palette='viridis')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Continent', fontsize=12)\n",
    "plt.ylabel('Points (Ind for each Artist/Nat)', fontsize=12)\n",
    "plt.title('Distribution of Points (Ind for each Artist/Nat) per Continent', fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Displaying average Points per continent\n",
    "avg_points_per_continent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1082d4f2",
   "metadata": {},
   "source": [
    "we can see a huge difference, so it shows artist is an important factor for cross-reginal popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c2eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA Test\n",
    "f_stat, p_value = stats.f_oneway(*(spotify_song_data['Points (Ind for each Artist/Nat)'][spotify_song_data['Continent'] == continent] for continent in spotify_song_data['Continent'].unique()))\n",
    "\n",
    "(f_stat, p_value)\n",
    "\n",
    "# Since the p-value is much smaller than the common significance level\n",
    "\n",
    "# This shows that the continent may indeed be related to the Points of the song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cbcb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Besides, nationality would like to be a factor\n",
    "artist_count_per_nationality = spotify_song_data['Nationality'].value_counts()\n",
    "\n",
    "# Selecting the top 10 nationalities that have the most artists\n",
    "top_nationalities_by_count = artist_count_per_nationality.head(10).index\n",
    "\n",
    "# Calculating the average points for these top nationalities\n",
    "avg_points_top_nationalities = spotify_song_data[spotify_song_data['Nationality'].isin(top_nationalities_by_count)].groupby('Nationality')['Points (Ind for each Artist/Nat)'].mean().sort_values(ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=avg_points_top_nationalities.index, y=avg_points_top_nationalities.values, palette='viridis')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Nationality', fontsize=12)\n",
    "plt.ylabel('Average Points (Ind for each Artist/Nat)', fontsize=12)\n",
    "plt.title('Average Points for Top 10 Nationalities (by Artist Count)', fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Displaying the data\n",
    "avg_points_top_nationalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fffa18b",
   "metadata": {},
   "source": [
    "Can we figure out which artists or genres are going to be popular in 2024 given the historic data from 2017?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a4b706",
   "metadata": {},
   "source": [
    "###### Data preprogressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column for each artists' average score\n",
    "\n",
    "# Step 1: Calculate the average points for each artist\n",
    "artist_avg_points = spotify_song_data.groupby('Artist (Ind.)')['Points (Total)'].mean()\n",
    "\n",
    "# Step 2: Function that returns the average points of artists\n",
    "def get_artist_average_points(artists):\n",
    "    # For multiple artists, we calculate the mean of their average points\n",
    "    artist_list = artists.split(\", \")  # Assuming artists are separated by \", \"\n",
    "    avg_points_list = [artist_avg_points.get(artist, 0) for artist in artist_list]\n",
    "    return sum(avg_points_list) / len(avg_points_list) if avg_points_list else 0\n",
    "\n",
    "# Step 3: Apply the function to the 'Artists' column\n",
    "spotify_song_data['Artist_Average_Points'] = spotify_song_data['Artists'].apply(get_artist_average_points)\n",
    "\n",
    "# Show the first few rows of the dataframe to verify the new column\n",
    "spotify_song_data[['Artists', 'Artist_Average_Points']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cb80d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_one_hot = pd.get_dummies(spotify_song_data, columns=['Continent'])\n",
    "\n",
    "# Applying one-hot encoding to the 'Continent' column and adding it to the original dataframe\n",
    "spotify_song_data = pd.concat([spotify_song_data, pd.get_dummies(spotify_song_data['Continent'], prefix='Continent')], axis=1)\n",
    "\n",
    "spotify_song_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9debe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Grouping the data by artist and calculating the total points\n",
    "artist_total_points = spotify_song_data.groupby('Artist (Ind.)')['Points (Ind for each Artist/Nat)'].sum()\n",
    "\n",
    "# Step 2: Creating a new column in the original dataframe that maps the total points for each artist\n",
    "spotify_song_data['Artist_Total_Points'] = spotify_song_data['Artist (Ind.)'].map(artist_total_points)\n",
    "\n",
    "spotify_song_data[['Artist (Ind.)', 'Artist_Total_Points']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting year and month\n",
    "spotify_song_data['Year'] = pd.to_datetime(spotify_song_data['Date']).dt.year\n",
    "spotify_song_data['Month'] = pd.to_datetime(spotify_song_data['Date']).dt.month\n",
    "\n",
    "spotify_song_data[['Date', 'Year', 'Month']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abf6583",
   "metadata": {},
   "source": [
    "###### Model: logistic regression, random forest, decision tree, naive bayes(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497dad72",
   "metadata": {},
   "source": [
    "我们目前处理了三个因素，Artist_Average_Points, Artist_Total_Points, different continent. \n",
    "现在我对2017年1月-2017年12月的数据作为训练集进行学习，并根据2023年1月到2023年5月的数据作为对照集测试，\n",
    "model用logistic regression, random forest, decision tree, naive bayes，把Point前25%的歌曲表示为流行，预测歌曲是否流行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faedeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organized Code for the Entire Process\n",
    "\n",
    "# 1. Data Preprocessing\n",
    "\n",
    "# Extracting year and month from the 'Date' column\n",
    "spotify_song_data['Year'] = pd.to_datetime(spotify_song_data['Date']).dt.year\n",
    "spotify_song_data['Month'] = pd.to_datetime(spotify_song_data['Date']).dt.month\n",
    "\n",
    "# Defining the target variable based on the top 25% of points\n",
    "threshold = spotify_song_data['Points (Total)'].quantile(0.75)\n",
    "spotify_song_data['Popular'] = (spotify_song_data['Points (Total)'] >= threshold).astype(int)\n",
    "\n",
    "# 2. Feature Selection and Dataset Splitting\n",
    "\n",
    "# Selecting features and target\n",
    "continent_features = [col for col in spotify_song_data.columns if col.startswith('Continent_')]\n",
    "features = ['Artist_Average_Points', 'Artist_Total_Points'] + continent_features\n",
    "target = 'Popular'\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "train_data = spotify_song_data[(spotify_song_data['Year'] >= 2017)]\n",
    "#                                & (spotify_song_data['Year'] <= 2022)]\n",
    "test_data = spotify_song_data[(spotify_song_data['Year'] == 2023)]\n",
    "\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]\n",
    "X_test = test_data[features]\n",
    "y_test = test_data[target]\n",
    "\n",
    "# Normalizing the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 3. Model Training\n",
    "\n",
    "# declare model:\n",
    "# Training the logistic regression model\n",
    "lr_model = LogisticRegression(random_state=0, class_weight='balanced', verbose=1)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# random forest model training\n",
    "rf_model = RandomForestClassifier(random_state=0, class_weight='balanced', verbose=1)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# decision tree model training\n",
    "dt_model = DecisionTreeClassifier(random_state=0, class_weight='balanced')\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Naive Bayes model training\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Model Evaluation\n",
    "print(f\"{' Model Evaluation Results ':-^60}\\n\")\n",
    "for model in [lr_model, rf_model, dt_model, nb_model]:\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    print(f'Model: {model.__class__.__name__}')\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'Classification Report:\\n {classification_rep}\\n')\n",
    "print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f16a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation_report(accuracy, classification_rep):\n",
    "    \"\"\"\n",
    "    Print the evaluation report in a formatted manner.\n",
    "\n",
    "    Parameters:\n",
    "    accuracy (float): The accuracy score of the model.\n",
    "    classification_rep (str): The classification report as a string.\n",
    "    \"\"\"\n",
    "    print(f\"{' Model Evaluation Results ':-^60}\\n\")\n",
    "    print(f\"Overall Accuracy: {accuracy:.2%}\\n\")\n",
    "    print(\"Detailed Classification Report:\")\n",
    "    print(classification_rep)\n",
    "    print(\"-\"*60)\n",
    "\n",
    "# 4. Model Evaluation\n",
    "\n",
    "# Evaluating the model on the test set\n",
    "y_pred = lr_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Printing the evaluation report using the new function\n",
    "print_evaluation_report(accuracy, classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7286ee",
   "metadata": {},
   "source": [
    "### Analyse regional result\n",
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c459710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data_region = song_data.copy()\n",
    "# print the rows where the Date ends with '06/2023'\n",
    "\n",
    "song_data_region.head()\n",
    "# remove the song with same id, same date\n",
    "song_data_region = song_data_region.drop_duplicates(subset=['id', 'Date'], keep='first')\n",
    "feature_columns = ['Danceability', 'Energy', 'Loudness', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Valence', 'Continent', 'Date', 'id']\n",
    "target_column = ['Points (Total)']\n",
    "song_data_region = song_data_region[feature_columns + target_column]\n",
    "\n",
    "# remove duplicates\n",
    "song_data_region = song_data_region.drop_duplicates()\n",
    "song_data_region['Year'] = song_data_region['Date'].str.split('/').str[2].astype(int)\n",
    "song_data_region['Month'] = song_data_region['Date'].str.split('/').str[1].astype(int)\n",
    "song_data_region['Day'] = song_data_region['Date'].str.split('/').str[0].astype(int)\n",
    "\n",
    "# drop date\n",
    "song_data_region = song_data_region.drop(columns=['Date'])\n",
    "\n",
    "# drop the row that continent is unknown\n",
    "song_data_region = song_data_region[song_data_region['Continent'] != 'Unknown']\n",
    "\n",
    "song_data_region.reset_index(drop=True, inplace=True)\n",
    "# print rows where year = 2023 and month = 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b889833",
   "metadata": {},
   "source": [
    "#### Visualize the result\n",
    "Typically balanced despite of some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb4182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series visualization\n",
    "# plot the total number of songs by year and month\n",
    "# group by year and month\n",
    "line_graph_sum = song_data_region.groupby(['Year', 'Month']).size().reset_index(name='Number of Songs')\n",
    "\n",
    "# combine year and month\n",
    "line_graph_sum['Year-Month'] = line_graph_sum['Year'].astype(str) + '-' + line_graph_sum['Month'].astype(str)\n",
    "line_graph_data = line_graph_sum.drop(columns=['Year', 'Month'])\n",
    "line_graph_data.tail(10)\n",
    "# plot the line graph\n",
    "plt.figure(figsize=(20, 10))\n",
    "x = line_graph_data['Year-Month']\n",
    "y = line_graph_data['Number of Songs']\n",
    "plt.plot(x, y)\n",
    "plt.xticks(x[::5])\n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('Number of Songs')\n",
    "plt.title('Total Number of Songs by Year and Month')\n",
    "plt.show()\n",
    "line_graph_data.tail(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da5bab",
   "metadata": {},
   "source": [
    "### Analyse points of different regions over time\n",
    "In visualisation stage, we can not see any relations between the popularity of music in one continent and the popularity of music in other continents as we lack of information about that song in other continent\n",
    "For the time trend in terms of daily points, we can see that the average points across each day is quite stable, we can not make a conclusion that the popularity of music will increase or decrease in specific time period\n",
    "\n",
    "### Analyse the user's streams over time\n",
    "In the graph and data, we extract top 30% of the average score in that month. We assume that if the average score of the songs is high, it means that the user to spend longer time to listen to the user.\n",
    "We can see that there is lower average score in Month 1,2,9,12. So the average song quality maynot be good in these months. This could be an indicator that the user may not spend longer time to listen to the user.\n",
    "In 3, 6, 7, 10, 11, the average score is higher and that could increase the opportunity for the user to spend longer time to listen to the music. Publishing the music in these months could be a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e975a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mode(Enum):\n",
    "    MEAN: str = 'Average Points'\n",
    "    MEDIAN: str = 'Median Points'\n",
    "    SUM: str = 'Total Points'\n",
    "\n",
    "class GraphType(Enum):\n",
    "    SUBPLOTS: str = 'Subplots'\n",
    "    ONE_PLOT: str = 'One Plot'\n",
    "\n",
    "# grab top n average points of the songs in each continent in each year and month\n",
    "def top_n_song_points(data: pd.DataFrame, n: int = 10):\n",
    "    region_points = song_data_region.groupby(['Year', 'Month', 'Continent', 'id'])['Points (Total)'].max()\n",
    "    region_points_df = region_points.reset_index(name='Max Points')\n",
    "    top_n_songs_points = region_points_df.sort_values(by=['Year', 'Month', 'Continent', 'Max Points'], ascending=False)\n",
    "    top_n_songs_points = top_n_songs_points.groupby(['Year', 'Month', 'Continent']).head(n)\n",
    "    top_n_songs_points = top_n_songs_points.reset_index(drop=True)\n",
    "    return top_n_songs_points\n",
    "\n",
    "def line_graph_for_time_series(data: pd.DataFrame, mode = Mode.MEAN, outlier_percent: float = 0.25, xticks_interval: int = 5, day: bool = False, date_point_quantile: float = 0.0):\n",
    "    group_by_columns = ['Year', 'Month'] if not day else ['Year', 'Month', 'Day']\n",
    "    merged_time_column = 'Year-Month' if not day else 'Year-Month-Day'\n",
    "    # create a data with year, month and the max points of the song in each continent in each year and month\n",
    "    line_graph_points = data.groupby(group_by_columns + ['id'])['Points (Total)'].max()\n",
    "    line_graph_points = line_graph_points.reset_index(name='Max Points')\n",
    "    # drop last outlier_percent of the points in each year and month to remove outliers\n",
    "    line_graph_points = line_graph_points.sort_values(by=group_by_columns + ['Max Points'], ascending=False)\n",
    "    point_threshold = line_graph_points.groupby(group_by_columns)['Max Points'].quantile(outlier_percent)\n",
    "    line_graph_points = line_graph_points.merge(point_threshold, on=group_by_columns, suffixes=('', '_threshold'))\n",
    "    line_graph_points = line_graph_points[line_graph_points['Max Points'] >= line_graph_points['Max Points_threshold']]\n",
    "    line_graph_points = line_graph_points.drop(columns=['Max Points_threshold'])\n",
    "    line_graph_points = line_graph_points.reset_index(drop=True)\n",
    "    line_graph_points = line_graph_points.groupby(group_by_columns)['Max Points']\n",
    "    \n",
    "    if mode == Mode.MEAN:\n",
    "        line_graph_points = line_graph_points.mean()\n",
    "    elif mode == Mode.MEDIAN:\n",
    "        line_graph_points = line_graph_points.median()\n",
    "    elif mode == Mode.SUM:\n",
    "        line_graph_points = line_graph_points.sum()\n",
    "    \n",
    "    line_graph_points = line_graph_points.reset_index(name= mode.value)\n",
    "    if not day:\n",
    "        line_graph_points['Year-Month'] = line_graph_points['Year'].astype(str) + '-' + line_graph_points['Month'].astype(str)\n",
    "    else:\n",
    "        line_graph_points['Year-Month-Day'] = line_graph_points['Year'].astype(str) + '-' + line_graph_points['Month'].astype(str) + '-' + line_graph_points['Day'].astype(str)\n",
    "    line_graph_points = line_graph_points.drop(columns=group_by_columns)\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    x = line_graph_points[merged_time_column]\n",
    "    y = line_graph_points[mode.value]\n",
    "    plt.plot(x, y, label=f'Top {100 - outlier_percent*100}% {mode.value} Songs')\n",
    "    plt.xticks(x[::xticks_interval], rotation=90)\n",
    "    plt.xlabel(str(merged_time_column))\n",
    "    plt.ylabel(mode.value)\n",
    "    title = f'{mode.value} by Year and Month' if not day else f'{mode.value} by Year, Month and Day'\n",
    "    plt.title(f'{title}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # print the time which is top 20% of the points in each year and month\n",
    "    top_10_percent_points_time_period = line_graph_points[line_graph_points[mode.value] >= line_graph_points[mode.value].quantile(date_point_quantile)]\n",
    "\n",
    "    # split the year-month column into year and month\n",
    "    top_10_percent_points_time_period[group_by_columns] = top_10_percent_points_time_period[merged_time_column].str.split('-', expand=True)\n",
    "    top_10_percent_points_time_period = top_10_percent_points_time_period.drop(columns=[merged_time_column])\n",
    "    # change all the columns in group_by_columns to int\n",
    "    top_10_percent_points_time_period[group_by_columns] = top_10_percent_points_time_period[group_by_columns].astype(int)\n",
    "    # sort by year and month\n",
    "    top_10_percent_points_time_period = top_10_percent_points_time_period.sort_values(by=group_by_columns, ascending=False)\n",
    "    display(pd.DataFrame(top_10_percent_points_time_period))\n",
    "    # count the number of same month or (year) in current record\n",
    "    if not day:\n",
    "        # group the record by month and conunt the number of same month, keep month, and count only\n",
    "        top_10_percent_points_time_period = top_10_percent_points_time_period.groupby(group_by_columns[1]).size().reset_index(name='Count')\n",
    "        display(pd.DataFrame(top_10_percent_points_time_period).style.hide_index())\n",
    "        \n",
    "\n",
    "def line_graph_for_continents(data: pd.DataFrame, mode = Mode.MEAN, graph_type = GraphType.SUBPLOTS, outlier_percent: float = 0.25, n: int = -1, xticks_interval: int = 5):\n",
    "    assert 0 <= outlier_percent <= 1, 'outlier_percent must be between 0 and 1'\n",
    "    # create a data with year, month, continent and the max points of the song in each continent in each year and month\n",
    "    line_graph_region_points = data.groupby(['Year', 'Month', 'Continent', 'id'])['Points (Total)'].max()\n",
    "    line_graph_region_points = line_graph_region_points.reset_index(name='Max Points')\n",
    "    print(\"Before removing outliers: \", line_graph_region_points.shape)\n",
    "    # drop last 25% of the points in each continent in each year and month to remove outliers\n",
    "    line_graph_region_points = line_graph_region_points.sort_values(by=['Year', 'Month', 'Continent', 'Max Points'], ascending=False)\n",
    "    point_threshold = line_graph_region_points.groupby(['Year', 'Month', 'Continent'])['Max Points'].quantile(outlier_percent)\n",
    "    line_graph_region_points = line_graph_region_points.merge(point_threshold, on=['Year', 'Month', 'Continent'], suffixes=('', '_threshold'))\n",
    "    line_graph_region_points = line_graph_region_points[line_graph_region_points['Max Points'] >= line_graph_region_points['Max Points_threshold']]\n",
    "    line_graph_region_points = line_graph_region_points.drop(columns=['Max Points_threshold'])\n",
    "    line_graph_region_points = line_graph_region_points.reset_index(drop=True)\n",
    "    print(\"After removing outliers: \", line_graph_region_points.shape)\n",
    "    line_graph_region_points = line_graph_region_points.groupby(['Year', 'Month', 'Continent'])['Max Points']\n",
    "    \n",
    "    if mode == Mode.MEAN:\n",
    "        line_graph_region_points = line_graph_region_points.mean()\n",
    "    elif mode == Mode.MEDIAN:\n",
    "        line_graph_region_points = line_graph_region_points.median()\n",
    "    elif mode == Mode.SUM:\n",
    "        line_graph_region_points = line_graph_region_points.sum()\n",
    "    line_graph_region_points = line_graph_region_points.reset_index(name= mode.value)\n",
    "    line_graph_region_points['Year-Month'] = line_graph_region_points['Year'].astype(str) + '-' + line_graph_region_points['Month'].astype(str)\n",
    "    line_graph_region_points = line_graph_region_points.drop(columns=['Year', 'Month'])\n",
    "    if graph_type == GraphType.SUBPLOTS:\n",
    "        # plot the multiple line graph for each continent in each subplot\n",
    "        plt.figure(figsize=(30, 10))\n",
    "        for i, continent in enumerate(line_graph_region_points['Continent'].unique(), 1):\n",
    "            plt.subplot(3, 3, i)\n",
    "            x = line_graph_region_points[line_graph_region_points['Continent'] == continent]['Year-Month']\n",
    "            y = line_graph_region_points[line_graph_region_points['Continent'] == continent][mode.value]\n",
    "            plt.plot(x, y, label=f'Top {100 - outlier_percent*100}% {mode.value} in {continent}')\n",
    "            plt.xticks(x[::xticks_interval], rotation=90)\n",
    "            if n != -1:\n",
    "                plt.title(f'Top {n} {mode.value} Songs in {continent}')\n",
    "                top_n_songs_points = top_n_song_points(data, n)\n",
    "                top_n_songs_points = top_n_songs_points.groupby(['Year', 'Month', 'Continent'])['Max Points'].mean()\n",
    "                top_n_songs_points = top_n_songs_points.reset_index(name='Average Points')\n",
    "                top_n_songs_points['Year-Month'] = top_n_songs_points['Year'].astype(str) + '-' + top_n_songs_points['Month'].astype(str)\n",
    "                top_n_songs_points = top_n_songs_points.drop(columns=['Year', 'Month'])\n",
    "                plt.plot(top_n_songs_points[top_n_songs_points['Continent'] == continent]['Year-Month'], \n",
    "                         top_n_songs_points[top_n_songs_points['Continent'] == continent]['Average Points'], \n",
    "                         label=f'Top {n} Average Points Songs in {continent}')\n",
    "            else:\n",
    "                plt.title(f'{mode.value} by Year and Month in {continent}')\n",
    "            plt.xlabel('Year-Month')\n",
    "            plt.ylabel(mode.value)\n",
    "            plt.legend()\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    elif graph_type == GraphType.ONE_PLOT:\n",
    "        # plot another line graph for each continent in one plot\n",
    "        plt.figure(figsize=(30, 10))\n",
    "        for continent in line_graph_region_points['Continent'].unique():\n",
    "            x = line_graph_region_points[line_graph_region_points['Continent'] == continent]['Year-Month']\n",
    "            y = line_graph_region_points[line_graph_region_points['Continent'] == continent][mode.value]\n",
    "            plt.plot(x, y, label=continent)\n",
    "            plt.xticks(x[::xticks_interval], rotation=90)\n",
    "        plt.xlabel('Year-Month')\n",
    "        plt.ylabel(mode.value)\n",
    "        plt.title(f'{mode.value} by Year and Month')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "line_graph_for_continents(song_data_region, mode=Mode.MEDIAN, graph_type=GraphType.SUBPLOTS, outlier_percent=0.75, n=100, xticks_interval=3)\n",
    "line_graph_for_continents(song_data_region, mode=Mode.MEDIAN, graph_type=GraphType.ONE_PLOT, outlier_percent=0.75, n=100, xticks_interval=3)\n",
    "# line_graph_for_time_series(song_data_region, mode=Mode.MEAN, outlier_percent=0.75, xticks_interval=30, day=True)\n",
    "line_graph_for_time_series(song_data_region, mode=Mode.MEDIAN, outlier_percent=0.75, xticks_interval=1, date_point_quantile=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aede344b",
   "metadata": {},
   "source": [
    "#### Time series analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb0a0ce",
   "metadata": {},
   "source": [
    "##### Visualize the number of points of different months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf5554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution graph for each year and month versus score\n",
    "def plot_distribution_graph_for_year_month(song_data_region: pd.DataFrame, year: int, month: int):\n",
    "    data = song_data_region.groupby(['Year', 'Month', 'Continent', 'id'])['Points (Total)'].mean()\n",
    "    data = data.reset_index(name='Average Points')\n",
    "    mean = data[(data['Year'] == year) & (data['Month'] == month)]['Average Points'].mean()\n",
    "    median = data[(data['Year'] == year) & (data['Month'] == month)]['Average Points'].median()\n",
    "    std = data[(data['Year'] == year) & (data['Month'] == month)]['Average Points'].std()\n",
    "    q1 = data[(data['Year'] == year) & (data['Month'] == month)]['Average Points'].quantile(0.25)\n",
    "    q3 = data[(data['Year'] == year) & (data['Month'] == month)]['Average Points'].quantile(0.75)\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.displot(data[(data['Year'] == year) & (data['Month'] == month)]['Average Points'], kde=True)\n",
    "    plt.xlim(0, 200)\n",
    "    plt.xlabel('Average Points')\n",
    "    plt.ylabel('Number of Songs')\n",
    "    plt.title(f'Distribution of Average Points in {year}-{month}')\n",
    "    # legend the mean, median and standard deviation\n",
    "    plt.axvline(mean, color='red', label='Mean')\n",
    "    plt.axvline(median, color='green', label='Median')\n",
    "    plt.axvline(q1, color='purple', label='Q1')\n",
    "    plt.axvline(q3, color='purple', label='Q3')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    display(pd.DataFrame({'Mean': [mean], 'Median': [median], 'Standard Deviation': [std], 'Q1': [q1], 'Q3': [q3]}))\n",
    "\n",
    "def plot_distribution_graph_for_year(song_data_region: pd.DataFrame, year: int):\n",
    "    sns.set()\n",
    "    data = song_data_region.groupby(['Year', 'Month', 'Continent', 'id'])['Points (Total)'].mean()\n",
    "    data = data.reset_index(name='Average Points')\n",
    "\n",
    "    fig, axes = plt.subplots(4, 3, figsize=(30, 30))\n",
    "    for i, month in enumerate(range(1, 13), 1):\n",
    "        sub_data = data[(data['Year'] == year) & (data['Month'] == month)]['Average Points']\n",
    "        sns.histplot(sub_data, kde=True, ax=axes[(i-1)//3, (i-1)%3])\n",
    "        axes[(i-1)//3, (i-1)%3].set_xlim(0, 200)\n",
    "        axes[(i-1)//3, (i-1)%3].set_xlabel('Average Points')\n",
    "        axes[(i-1)//3, (i-1)%3].set_ylabel('Number of Songs')\n",
    "        axes[(i-1)//3, (i-1)%3].set_title(f'Distribution of Average Points in {year}-{month}')\n",
    "    plt.show()\n",
    "    \n",
    "plot_distribution_graph_for_year(song_data_region, 2018)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
